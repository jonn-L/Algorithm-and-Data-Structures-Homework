===============================================================================

a) Implement all four methods to compute Fibonacci numbers that were discussed
in the lecture: (1) naive recursive, (2) bottom up, (3) closed form, and (4) 
using the matrix representation.

a) See Fibonacci.cpp

===============================================================================

b) Sample and measure the running times of all four methods for increasing n. 
For each method, stop the sampling when the running time exceeds some fixed 
amount of time (same for all methods). If needed, you may use classes or 
structs for large numbers (self-written or library components). Create a table
with your results (max. 1 page).

b) See Time_Computations.xlsx after running computationTimes.py

===============================================================================

c) For the same n, do all methods always return the same Fibonacci number? 
Eplain your answer.

c) Due to the way the algorithms work, the output will always be the same for 
all of them, except for Closed Form. As n grows, the output of the Closed Form 
becomes less accurate as a result of how numbers with decimal points are 
stored in computers; only 32 bits are used which leads to the less precise
representation of floating point numbers as n grows.

===============================================================================

d) Plot your results in a line plot, such that the four approaches can be 
easily compared. Briefly interpret your results.

d) See computationTimes.py for plot.

Naive Recursion - looking at the line of naive recursion we can see that it 
it sky-rockets instantly and has missing values after n ~30. This is a result 
of how inefficent it due to having a time complexity of n^2.

Bottom Up - this algorithm has a time complexity of O(n) and as such, it 
performs pretty well as n grows. After some point though, as in the Naive 
Recursion, time gaps do begin to show.

Closed Form & Matrix Representation - these algorithms both have a time 
complexity of O(nlogn) and it is to no one's surprise that they are the most
efficient algorithms out of the ones here. This becomes especially obvious when
looking at the graph.  

===============================================================================
